import numpy as np
import json
from itertools import product

from backend import Executor


class ClusterGenerator:
    '''
    Generate clustering data and models.

    Data are transformed based on a feature transformation and a distance
    metric. Samples of configurations are generated by ConfigSampler.
    Feature transformations and distances can be precomputed and cached.

    Parameters:
        X : ndarray of shape (n_observations, n_features)
            The data matrix to be clustered.
        options : dict
            A dictionary specifying the parameter options for the clustering
            algorithms, the feature transformations, the distance metrics,
            and the observation sampling rate. Values of type dict specify
            a categorical distribution to sample from. The distribution dict
            can either contain 'choices' and optionally 'weights' keys with
            array-like values, or contain 'min_val' and 'max_val' keys with
            integer values. The values of 'weights' need to be non-negative.
        parameters : dict
            A dictionary specifying the required parameters for the clustering
            algorithms, feature transformations and distance metrics.
            Extends and/or overwrites the default parameters dict.
        definitions : dict
            A dictionary mapping function names of clustering algorithms,
            feature transformations, and distance metrics to functions.
            Extends and/or overwrites the default definitions dict.
        features : dict
            A dict mapping feature config strings to feature matrices.
            Feature configs contain a 'transformation' key with the name of
            the transformation as the value and a
            key with a dictionary mapping parameter names to parameter values.
            Feature matrices are ndarrays of shape (n_observations, n_features).
        distances : dict
            A dict mapping distance config strings to distance matrices.
            Distance configs contain a 'transformation',
            'transformation_parameters', 'metric' and 'metric_parameters'.
            Distance matrices are ndarrays of shape
            (n_observations, n_observations).
        precompute : {'features', 'distances', None}
            If precompute is set to 'features', all the feature transformations
            are precomputed and stored in the features dictionary.
            If set to 'distances', all feature transformations and all distances
            are precomputed and stored in the distances dictionary.
    '''

    def __init__(self,
                 X,
                 options,
                 parameters=None,
                 features=None,
                 distances=None,
                 precompute=None,
                 definitions=None):
        self.X = X
        self.configs = ConfigSampler(options, len(X), parameters)
        self.executor = Executor(definitions)
        self.features = features or {}
        self.distances = distances or {}
        self.precompute = precompute
        if self.precompute:
            self._precompute()

    def _precompute(self):
        if self.precompute in ('features', 'distances'):
            feature_configs = self.configs.get_feature_configs()
            self._precompute_features(feature_configs)
        if self.precompute == 'distances':
            distance_configs = self.configs.get_distance_configs(feature_configs)
            self._precompute_distances(distance_configs)

    def _precompute_features(self, configs):
        for config in configs:
            key = _get_feature_key(config)
            if key not in self.features:
                self.features[key] = self._compute_transformation(self.X, config)

    def _precompute_distances(self, configs):
        for config in configs:
            key = _get_distance_key(config)
            if key not in self.distances:
                X = self.features[_get_feature_key(config)]
                self.distances[key] = self._compute_distances(X, config)

    def sample(self):
        '''Sample a configuration, transform data and fit a clustering model.'''
        return self.cluster(self.configs.sample())

    def cluster(self, config):
        '''Transform data and fit a clustering model data from a configuration.'''
        X = self._make_data(config)
        model = self.executor.fit_model(config, X)
        return {'model': model, 'config': config, 'data': X}

    def _make_data(self, config):
        if self.precompute:
            return self._get_precomputed(config)

        X = self._index_feature_matrix(self.X, config)
        X = self._compute_transformation(X, config)
        X = self._compute_distances(X, config)
        return X

    def _get_precomputed(self, config):
        distances = self.distances.get(_get_distance_key(config), None)
        if distances is not None:
            return self._index_distance_matrix(distances, config)

        features = self.features.get(_get_feature_key(config), None)
        if config.get('metric', None) is not None:
            distances = self._compute_distances(features, config)
            return self._index_distance_matrix(distances, config)

        return self._index_feature_matrix(features, config)

    def _index_distance_matrix(self, X, config):
        indexes = config.get('sample_indexes', None)
        if indexes is not None:
            return X[indexes][:, indexes]
        return X

    def _index_feature_matrix(self, X, config):
        indexes = config.get('sample_indexes', None)
        if indexes is not None:
            return X[indexes]
        return X

    def _compute_distances(self, X, config):
        if config.get('metric', None) is None:
            return X
        return self.executor.compute_distances(config, X)

    def _compute_transformation(self, X, config):
        transformation = config['transformation']
        if transformation is None:
            return X
        return self.executor.transform(config, X)


class ConfigSampler:
    '''
    Sample clustering configurations.

    A configuration consists of a paremetrized clustering algorithm,
    a parametrized feature transformation, a parametrized distance metric
    if the clustering algorithm requires distances, and the indexes of a subset
    of the observations.
    
    Parameters:
        options : dict
            A dictionary specifying the parameter options for the clustering
            algorithms, the feature transformations, the distance metrics,
            and the observation sampling rate. Values of type dict specify
            a categorical distribution to sample from. The distribution dict
            can either contain 'choices' and optionally 'weights' keys with
            array-like values, or contain 'min_val' and 'max_val' keys with
            integer values. The values of 'weights' need to be non-negative.
        data_size : int
            The number of observations to be clustered.
        parameters : dict
            A dictionary specifying the required parameters for the clustering
            algorithms, feature transformations and distance metrics.
            Extends and/or overwrites the default parameters items.
    '''

    parameters = {'hac': ['linkage', 'n_clusters', 'metric'],
                  'hacsingle': ['n_clusters', 'metric'],
                  'hacaverage': ['n_clusters', 'metric'],
                  'kmeans': ['n_clusters'],
                  'mbkmeans': ['n_clusters'],
                  'dbscan': ['eps', 'min_samples', 'metric'],
                  'rbf': ['gamma'],
                  'svd': ['n_components'],
                  'autoencoder': ['layer_dims'],
                  'convautoencoder': ['kernel_shapes', 'h_dim']}

    def __init__(self,
                 options,
                 data_size,
                 parameters=None):
        self.options = options
        self.indexes = np.arange(data_size)
        if parameters is not None:
            self.parameters = {**self.parameters, **parameters}

    def get_feature_configs(self):
        '''Return a list of all the feature transformation configurations.'''
        transformations = self.options.get('transformation', None)
        if transformations is None:
            return [{'transformation': None, 'transformation_parameters': {}}]

        feature_configs = []
        transformations = self._get_param_values(transformations)
        for transformation in transformations:
            for param_config in self._get_option_configs(transformation):
                config = {'transformation': transformation,
                          'transformation_parameters': param_config}
                feature_configs.append(config)

        return feature_configs

    def get_distance_configs(self, feature_configs=None):
        '''Return a list of all the distance configurations.'''
        if feature_configs is None:
            feature_configs = self.get_feature_configs()

        distance_configs = []
        metrics = self.options.get('metric', None)
        if metrics is None:
            return distance_configs

        metrics = self._get_param_values(metrics)
        for fconfig in feature_configs:
            for metric in metrics:
                for param_config in self._get_option_configs(metric):
                    dconfig = {**fconfig,
                               **{'metric': metric,
                                  'metric_parameters': param_config}}
                    distance_configs.append(dconfig)
        return distance_configs

    def _get_option_configs(self, option):
        param_dict = {}
        parameters = self.parameters.get(option, None)
        if parameters is not None:
            for parameter in parameters:
                param_dict[parameter] = self._get_param_values(
                        self.options.get(parameter, None))

        configs = []
        for param_values in product(*param_dict.values()):
            configs.append(dict(zip(param_dict.keys(), param_values)))
        return configs

    def _get_parameters(self, option):
        param_dict = {}
        parameters = self.parameters.get(option, None)
        if parameters is not None:
            for parameter in parameters:
                value = self.options.get(parameter, None)
                if isinstance(value, dict):
                    param_dict[parameter] = sample_categorical(**value)
                else:
                    param_dict[parameter] = value
        return param_dict

    def _get_param_values(self, parameter):
        if isinstance(parameter, dict):
            if 'choices' in parameter:
                values = parameter['choices']
            elif 'min_val' in parameter and 'max_val' in parameter:
                values = list(range(parameter['min_val'],
                                    parameter['max_val']))
            return values
        return [parameter]

    def _parse_option(self, option):
        value = self.options.get(option, None)
        if isinstance(value, dict):
            return sample_categorical(**value)
        return value

    def _get_indexes(self):
        rate = self.options.get('data_subsampling_rate', None)
        if rate is None:
            return
        if isinstance(rate, dict):
            rate = sample_categorical(rate)
        return _sample_indexes(self.indexes, rate)

    def sample(self):
        '''Sample and return a clustering configuration dict.'''
        model = self._parse_option('model')
        model_parameters = self._get_parameters(model)

        transformation = self._parse_option('transformation')
        transformation_parameters = self._get_parameters(transformation)

        metric = model_parameters.get('metric', None)
        metric_parameters = self._get_parameters(metric)

        indexes = self._get_indexes()

        return {'model': model,
                'model_parameters': model_parameters,
                'transformation': transformation,
                'transformation_parameters': transformation_parameters,
                'metric': metric,
                'metric_parameters': metric_parameters,
                'sample_indexes': indexes}

def sample_categorical(choices=None, weights=None,
                       min_val=1, max_val=10):
    '''
    Generate a sample from a categorical distribution.

    If the choices parameter is not None, a sample is selected from its items
    with probability proportional to the values in weights or uniform if
    weights is None.
    Otherwise the sample is selected from range(min_val, max_val)
    with uniform probability.

    Parameters:
        choices : array-like
            Items to be sampled.
        weights : array-like
            Categorical distribution parameters. Values need to be non-negative.
        min_val : int
            Minimum value (inclusive) of an integer range to sample from.
        max_val : int
            Maximum value (exclusive) of an integer range to sample from.
    '''
    if choices is not None:
        if weights is not None:
            weights = np.array(weights) / np.sum(weights)
        idx = np.random.choice(len(choices), p=weights)
        return choices[idx]
    return np.random.choice(range(min_val, max_val))

def _get_distance_key(config):
    return _serialize({'transformation': config.get('transformation', None),
                       'transformation_parameters':
                           config.get('transformation_parameters', {}),
                       'metric': config.get('metric', None),
                       'metric_parameters': config.get('metric_parameters', {})
                      })

def _get_feature_key(config):
    return _serialize({'transformation': config.get('transformation', None),
                       'transformation_parameters':
                           config.get('transformation_parameters', {})
                      })

def _sample_indexes(indexes, rate):
    if not rate:
        return indexes
    size = int(len(indexes) * (1.-rate))
    return np.sort(np.random.choice(indexes, size=size, replace=False))

def _serialize(dictionary):
    return json.dumps(dictionary, sort_keys=True)
